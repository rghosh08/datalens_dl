{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e7728e7-e62b-4b94-b3df-bf60beded501",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "#### This notebook pertains to non-deterministic clustering for novelty detection in unstructured log data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98b85f06-3da7-4b8c-bc4d-164adb67577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "582645a0-f78f-4ea0-9719-818508f36194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Load some categories from the training set\n",
    "categories = [\n",
    "    \"alt.atheism\",\n",
    "    \"talk.religion.misc\",\n",
    "    \"comp.graphics\",\n",
    "    \"sci.space\",\n",
    "]\n",
    "# Uncomment the following to do the analysis on all the categories\n",
    "# categories = None\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "946461d8-924e-4268-94e9-71de494f4c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387 documents\n",
      "4 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_20newsgroups(\n",
    "    subset=\"all\", categories=categories, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "print(\"%d documents\" % len(dataset.data))\n",
    "print(\"%d categories\" % len(dataset.target_names))\n",
    "print()\n",
    "\n",
    "labels = dataset.target\n",
    "true_k = np.unique(labels).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c12410a-229f-490d-91fe-b3d2e3b7ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "        max_df=0.5,\n",
    "        max_features=5,\n",
    "        min_df=2,\n",
    "        stop_words=\"english\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "170049ac-e133-4e5a-a942-517dca538e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 3387, n_features: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(dataset.data)\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4e3f255-292d-4817-9aa5-a8372371985e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing dimensionality reduction using LSA\n",
      "done in 0.006500s\n",
      "Explained variance of the SVD step: 43%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing dimensionality reduction using LSA\")\n",
    "t0 = time()\n",
    "# Vectorizer results are normalized, which makes KMeans behave as\n",
    "# spherical k-means for better results. Since LSA/SVD results are\n",
    "# not normalized, we have to redo the normalization.\n",
    "svd = TruncatedSVD()\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\n",
    "    \"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100))\n",
    ")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ac94610-776f-4942-876e-b9506d6ce009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# km = MiniBatchKMeans(\n",
    "#         n_clusters=true_k,\n",
    "#         init=\"k-means++\",\n",
    "#         n_init=1,\n",
    "#         init_size=1000,\n",
    "#         batch_size=1000,\n",
    "#         verbose=2,\n",
    "#     )\n",
    "gm = GaussianMixture(n_components=4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccc5c7b3-e51e-46f7-96e9-1aa3bcee29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Clustering sparse data with %s\" % km)\n",
    "# t0 = time()\n",
    "# km.fit(X)\n",
    "# print(\"done in %0.3fs\" % (time() - t0))\n",
    "# print()\n",
    "\n",
    "# print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "# print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "# print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "# print(\"Adjusted Rand-Index: %.3f\" % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "# print(\n",
    "#     \"Silhouette Coefficient: %0.3f\"\n",
    "#     % metrics.silhouette_score(X, km.labels_, sample_size=1000)\n",
    "# )\n",
    "\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70355c45-2b32-408a-bda8-c3c465fe2a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with GaussianMixture(n_components=4, random_state=0)\n",
      "done in 0.024s\n",
      "\n",
      "akaike information criterion: -24095.961\n",
      "bayesian information criterion: -23955.024\n",
      "\n",
      "['article', 'com', 'don', 'god', 'space']\n"
     ]
    }
   ],
   "source": [
    "print(\"Clustering sparse data with %s\" % gm)\n",
    "t0 = time()\n",
    "gm.fit(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "print(\"akaike information criterion: %0.3f\" % gm.aic(X))\n",
    "print(\"bayesian information criterion: %0.3f\" % gm.bic(X))\n",
    "print()\n",
    "terms = vectorizer.get_feature_names()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e8bcb55-7ec3-44ad-a875-cff249bb76c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98371332, -0.02074082],\n",
       "       [ 0.65360429,  0.73500612],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 0.84166877, -0.51921586]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e81f21a4-a36c-4ecc-b4be-d3f8e473f93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 7.49838739e-69, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.predict_proba([[1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79878c09-43a9-4d00-bdc1-1af44056a318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covariance_type': 'full',\n",
       " 'init_params': 'kmeans',\n",
       " 'max_iter': 100,\n",
       " 'means_init': None,\n",
       " 'n_components': 4,\n",
       " 'n_init': 1,\n",
       " 'precisions_init': None,\n",
       " 'random_state': 0,\n",
       " 'reg_covar': 1e-06,\n",
       " 'tol': 0.001,\n",
       " 'verbose': 0,\n",
       " 'verbose_interval': 10,\n",
       " 'warm_start': False,\n",
       " 'weights_init': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68a0e8cb-ba6f-4ddf-a034-f43684510009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5639151422404716"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.score(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2901d-5f02-409d-87ce-928af7ddda58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
